{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "MERGED_DATA_DIR = \"../../data/merged data\"\n",
    "OUTPUT_DIR = \"../../output/assumption\"\n",
    "\n",
    "# Load the dataset\n",
    "tnp_20 = pd.read_csv(os.path.join(MERGED_DATA_DIR, \"2020\", \"merged_tnp_data.csv\"))\n",
    "tnp_19 = pd.read_csv(os.path.join(MERGED_DATA_DIR, \"2019\", \"merged_tnp_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加年份指示变量\n",
    "tnp_20[\"is_2020\"] = 1\n",
    "tnp_19[\"is_2020\"] = 0\n",
    "\n",
    "scaler = StandardScaler()\n",
    "cols_to_scale = [\"daily_bus_rides\", \"rides\"]\n",
    "tnp_20[cols_to_scale] = scaler.fit_transform(tnp_20[cols_to_scale])\n",
    "tnp_19[cols_to_scale] = scaler.fit_transform(tnp_19[cols_to_scale])\n",
    "\n",
    "# 拼接数据\n",
    "merged_df = pd.concat([tnp_20, tnp_19], ignore_index=True)\n",
    "merged_df[\"price\"] = merged_df[\"fare\"] + merged_df[\"additional_charges\"]\n",
    "# merged_df['price'] = np.log1p(merged_df['price'])\n",
    "\n",
    "# 确保日期变量是 datetime 类型（后续 RDiT 会用到）\n",
    "merged_df[\"trip_start_date\"] = pd.to_datetime(merged_df[\"trip_start_date\"])\n",
    "\n",
    "# 创建工作日虚拟变量，drop_first=True 是为了避免虚拟变量陷阱\n",
    "day_dummies = pd.get_dummies(merged_df['day_of_week'], prefix='dow', drop_first=True)\n",
    "\n",
    "# 合并到原始数据中\n",
    "merged_df = pd.concat([merged_df, day_dummies], axis=1)\n",
    "\n",
    "# 创建地区虚拟变量，drop_first=True 是为了避免虚拟变量陷阱\n",
    "area_dummies = pd.get_dummies(merged_df['area_type'], prefix='at', drop_first=True)\n",
    "\n",
    "# 合并到原始数据中\n",
    "merged_df = pd.concat([merged_df, area_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总行数： 3187906\n",
      "是否有NaN： 0\n",
      "时间列范围： 2018-12-10 00:00:00 2020-02-05 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"数据总行数：\", len(merged_df))\n",
    "print(\"是否有NaN：\", merged_df[\"price\"].isna().sum())\n",
    "print(\"时间列范围：\", merged_df[\"trip_start_date\"].min(), merged_df[\"trip_start_date\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_controls = [\n",
    "    \"trip_seconds\", \"trip_miles\", \"trip_during_peak\"\n",
    "]\n",
    "\n",
    "weather_controls = [\n",
    "    \"Avg_Temp_C\", \"Precipitation_mm\",\n",
    "    \"Snowfall_mm\", \"Avg_Wind_Speed_mps\",\n",
    "]\n",
    "\n",
    "substitutes_controls = [\n",
    "    # \"total_rides\", \"taxi\",\n",
    "    \"rides\", \"daily_bus_rides\", \"taxi\",\n",
    "]\n",
    "\n",
    "day_of_week_controls = [\"dow_1\", \"dow_2\", \"dow_3\", \"dow_4\"]\n",
    "\n",
    "area_type_controls = [\"at_1\", \"at_2\"]\n",
    "\n",
    "control_vars = (\n",
    "    trip_controls\n",
    "    + weather_controls\n",
    "    + substitutes_controls\n",
    "    + day_of_week_controls\n",
    "    + area_type_controls\n",
    ")\n",
    "\n",
    "merged_df_0 = merged_df[merged_df[\"Cluster\"] == 0]\n",
    "merged_df_1 = merged_df[merged_df[\"Cluster\"] == 1]\n",
    "merged_df_2 = merged_df[merged_df[\"Cluster\"] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Bandwidth Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_dif_in_rdit(\n",
    "    df: pd.DataFrame,\n",
    "    outcome: str,\n",
    "    time_var: str,\n",
    "    treat_year_var: str,\n",
    "    cutoff_date,\n",
    "    placebo_cutoff_date=\"2019-01-07\",\n",
    "    heterogeneity_vars: list = None,\n",
    "    covariates: list = None,\n",
    "    trend_order: int = 1,\n",
    "    bandwidth: int = 29\n",
    "):\n",
    "    \"\"\"\n",
    "    估计Dif-in-RDiT模型，支持多个异质性变量（连续或虚拟变量）\n",
    "\n",
    "    数学模型：\n",
    "    Y_{it} = β0 + β1·Post_t + β2·TreatYear_i + β3·(Post_t·TreatYear_i)\n",
    "           + f(TFC_t) + f(TFC_t)·Post_t + f(TFC_t)·TreatYear_i + f(TFC_t)·Post_t·TreatYear_i\n",
    "           + ∑ δ_k·H_{ik} + ∑ θ_k·(Post_t·H_{ik}) + γ^T X + u_{it}\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import statsmodels.formula.api as smf\n",
    "\n",
    "    df = df.copy()\n",
    "    df[time_var] = pd.to_datetime(df[time_var])\n",
    "    cutoff_date = pd.to_datetime(cutoff_date)\n",
    "    placebo_cutoff_date = pd.to_datetime(placebo_cutoff_date)\n",
    "\n",
    "    df[\"cutoff_for_row\"] = df[treat_year_var].apply(\n",
    "        lambda x: cutoff_date if x == 1 else placebo_cutoff_date\n",
    "    )\n",
    "    df[\"days_from_cutoff\"] = (df[time_var] - df[\"cutoff_for_row\"]).dt.days\n",
    "    df = df[df[\"days_from_cutoff\"].between(-bandwidth, bandwidth)]\n",
    "\n",
    "    df[\"post_cutoff\"] = (df[\"days_from_cutoff\"] >= 0).astype(int)\n",
    "    df[\"post_treat\"] = df[\"post_cutoff\"] * df[treat_year_var]\n",
    "\n",
    "    trend_terms = []\n",
    "    for i in range(1, trend_order + 1):\n",
    "        base = f\"days_from_cutoff_pow{i}\"\n",
    "        df[base] = df[\"days_from_cutoff\"] ** i\n",
    "\n",
    "        post = f\"{base}_x_post\"\n",
    "        treat = f\"{base}_x_treat\"\n",
    "        post_treat = f\"{base}_x_post_treat\"\n",
    "\n",
    "        df[post] = df[base] * df[\"post_cutoff\"]\n",
    "        df[treat] = df[base] * df[treat_year_var]\n",
    "        df[post_treat] = df[base] * df[\"post_cutoff\"] * df[treat_year_var]\n",
    "\n",
    "        trend_terms += [base, post, treat, post_treat]\n",
    "\n",
    "    rhs = [\"post_cutoff\", treat_year_var, \"post_treat\"] + trend_terms\n",
    "\n",
    "    if covariates:\n",
    "        rhs += covariates\n",
    "\n",
    "    interaction_terms = []\n",
    "    if heterogeneity_vars:\n",
    "        for var in heterogeneity_vars:\n",
    "            rhs.append(var)  # H_k\n",
    "            inter = f\"post_cutoff:{var}\"  # Post_t * H_k\n",
    "            rhs.append(inter)\n",
    "            interaction_terms.append(inter)\n",
    "\n",
    "    formula = f\"{outcome} ~ \" + \" + \".join(rhs)\n",
    "    model = smf.ols(formula=formula, data=df).fit(cov_type='HC3')\n",
    "\n",
    "    summary_df = model.summary2().tables[1].copy()\n",
    "    summary_df.columns = summary_df.columns.astype(str)\n",
    "    summary_df = summary_df.rename(columns={\n",
    "        \"Coef.\": \"coef\",\n",
    "        \"Std.Err.\": \"std_err\",\n",
    "        \"P>|t|\": \"p_value\",\n",
    "        \"[0.025\": \"ci_lower\",\n",
    "        \"0.975]\": \"ci_upper\"\n",
    "    })\n",
    "    summary_df[\"variable\"] = summary_df.index\n",
    "    summary_df.reset_index(drop=True, inplace=True)\n",
    "    print(model.rsquared)\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_grouped_rdit_to_tex(\n",
    "    summary_df: pd.DataFrame,\n",
    "    file_path: str = \"grouped_rdit_table.tex\",\n",
    "    sig_levels: list = [0.1, 0.05, 0.01],\n",
    "    caption: str = \"Estimated effects of the congestion tax by income group.\",\n",
    "    label: str = \"tab:rdit_by_income\",\n",
    "    group_labels: dict = None,\n",
    "    group_obs: dict = None  # ✅ 新增参数：每组观测数\n",
    "):\n",
    "    import os\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "    def get_stars(p):\n",
    "        if p < sig_levels[2]: return '***'\n",
    "        elif p < sig_levels[1]: return '**'\n",
    "        elif p < sig_levels[0]: return '*'\n",
    "        return ''\n",
    "    \n",
    "    def get_stars_from_dict(d):\n",
    "        if 'p_value' in d:\n",
    "            p = d['p_value']\n",
    "        else:\n",
    "            if 'coef' in d and 'stderr' in d and d['stderr'] != 0:\n",
    "                import scipy.stats as stats\n",
    "                t_stat = d['coef'] / d['stderr']\n",
    "                p = 2 * (1 - stats.norm.cdf(abs(t_stat)))\n",
    "            else:\n",
    "                p = 1.0\n",
    "        return get_stars(p)\n",
    "\n",
    "    df = summary_df[summary_df[\"variable\"] == \"post_treat\"].copy()\n",
    "    groups = df[\"group\"].tolist()\n",
    "\n",
    "    columns = [group_labels.get(g, g) for g in groups] if group_labels else groups\n",
    "\n",
    "    coef_row = [\n",
    "        f\"{row['coef']:.3f}{get_stars(row['P>|z|'])}\"\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "    stderr_row = [\n",
    "        f\"({row['std_err']:.3f})\"\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    tex_lines = [\n",
    "        \"\\\\begin{table}[H]\\\\centering\",\n",
    "        f\"\\\\caption{{{caption}}}\",\n",
    "        f\"\\\\label{{{label}}}\",\n",
    "        \"\\\\footnotesize\",\n",
    "        f\"\\\\begin{{tabular}}{{l{'c' * len(columns)}}}\",\n",
    "        \"\\\\toprule\",\n",
    "        \" & \" + \" & \".join(columns) + \" \\\\\\\\\",\n",
    "        \"\\\\midrule\",\n",
    "        \"Post $\\\\times$ TreatYear & \" + \" & \".join(coef_row) + \" \\\\\\\\\",\n",
    "        \"Std. Error & \" + \" & \".join(stderr_row) + \" \\\\\\\\\",\n",
    "    ]\n",
    "\n",
    "    # ✅ 添加观测数行（如果有提供）\n",
    "    if group_obs:\n",
    "        obs_row = [\"Observations\"] + [str(group_obs.get(g, \"–\")) for g in groups]\n",
    "        tex_lines.append(\"\\\\midrule\")\n",
    "        tex_lines.append(\" & \".join(obs_row) + \" \\\\\\\\\")\n",
    "\n",
    "    tex_lines += [\n",
    "        \"\\\\bottomrule\",\n",
    "        \"\\\\end{tabular}\",\n",
    "        \"\\\\vspace{0.5em}\",\n",
    "        \"\\\\begin{minipage}{0.95\\\\textwidth}\\\\footnotesize\\\\textit{Notes:} Robust standard errors in parentheses. * $p < 0.1$, ** $p < 0.05$, *** $p < 0.01$.\\\\end{minipage}\",\n",
    "        \"\\\\end{table}\"\n",
    "    ]\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(tex_lines))\n",
    "\n",
    "    print(f\"LaTeX table saved to: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7795886814191689\n",
      "trip_seconds: 1457 unique values\n",
      "trip_miles: 2209763 unique values\n",
      "trip_during_peak: 2 unique values\n",
      "Avg_Temp_C: 69 unique values\n",
      "Precipitation_mm: 23 unique values\n",
      "Snowfall_mm: 14 unique values\n",
      "Avg_Wind_Speed_mps: 41 unique values\n",
      "rides: 5649 unique values\n",
      "daily_bus_rides: 7158 unique values\n",
      "taxi: 55 unique values\n",
      "dow_1: 2 unique values\n",
      "dow_2: 2 unique values\n",
      "dow_3: 2 unique values\n",
      "dow_4: 2 unique values\n",
      "at_1: 2 unique values\n",
      "at_2: 2 unique values\n",
      "0.8139738498096765\n",
      "0.7688939921582473\n",
      "0.7951670006904098\n",
      "{'Pooled': 1385310, 'Low Income': 53645, 'Mid Income': 410354, 'High Income': 921311}\n",
      "LaTeX table saved to: ../../output/regression/rdit_group_table.tex\n"
     ]
    }
   ],
   "source": [
    "# Step 1: 拟合模型，仅返回关键系数（post_treat + 异质性）\n",
    "summary_pooled = estimate_dif_in_rdit(\n",
    "    df=merged_df,\n",
    "    outcome=\"price\",\n",
    "    time_var=\"trip_start_date\",\n",
    "    treat_year_var=\"is_2020\",\n",
    "    cutoff_date=\"2020-01-06\",\n",
    "    placebo_cutoff_date=\"2019-01-07\",\n",
    "    covariates=control_vars,\n",
    "    trend_order=1,\n",
    "    bandwidth=15\n",
    ")\n",
    "\n",
    "for col in control_vars:\n",
    "    print(f\"{col}: {merged_df[col].nunique()} unique values\")\n",
    "\n",
    "summary_low = estimate_dif_in_rdit(\n",
    "    df=merged_df_0,\n",
    "    outcome=\"price\",\n",
    "    time_var=\"trip_start_date\",\n",
    "    treat_year_var=\"is_2020\",\n",
    "    cutoff_date=\"2020-01-06\",\n",
    "    placebo_cutoff_date=\"2019-01-07\",\n",
    "    covariates=control_vars,\n",
    "    trend_order=1,\n",
    "    bandwidth=15\n",
    ")\n",
    "\n",
    "summary_high = estimate_dif_in_rdit(\n",
    "    df=merged_df_1,\n",
    "    outcome=\"price\",\n",
    "    time_var=\"trip_start_date\",\n",
    "    treat_year_var=\"is_2020\",\n",
    "    cutoff_date=\"2020-01-06\",\n",
    "    placebo_cutoff_date=\"2019-01-07\",\n",
    "    covariates=control_vars,\n",
    "    trend_order=1,\n",
    "    bandwidth=15\n",
    ")\n",
    "\n",
    "summary_mid = estimate_dif_in_rdit(\n",
    "    df=merged_df_2,\n",
    "    outcome=\"price\",\n",
    "    time_var=\"trip_start_date\",\n",
    "    treat_year_var=\"is_2020\",\n",
    "    cutoff_date=\"2020-01-06\",\n",
    "    placebo_cutoff_date=\"2019-01-07\",\n",
    "    covariates=control_vars,\n",
    "    trend_order=1,\n",
    "    bandwidth=15\n",
    ")\n",
    "\n",
    "# Step 2: 导出表格\n",
    "# 提取主系数并合并\n",
    "rows = []\n",
    "for label, df in [(\"Pooled\", summary_pooled), (\"Low Income\", summary_low), (\"Mid Income\", summary_mid), (\"High Income\", summary_high)]:\n",
    "    row = df[df[\"variable\"] == \"post_treat\"].copy()\n",
    "    row[\"group\"] = label\n",
    "    rows.append(row)\n",
    "\n",
    "summary_df = pd.concat(rows)\n",
    "\n",
    "from pandas import Timestamp\n",
    "\n",
    "def count_bandwidth_sample(df, time_var, treat_year_var, cutoff_date, placebo_cutoff_date, bandwidth):\n",
    "    df = df.copy()\n",
    "    df[time_var] = pd.to_datetime(df[time_var])\n",
    "    df[\"cutoff_for_row\"] = df[treat_year_var].apply(\n",
    "        lambda x: Timestamp(cutoff_date) if x == 1 else Timestamp(placebo_cutoff_date)\n",
    "    )\n",
    "    df[\"days_from_cutoff\"] = (df[time_var] - df[\"cutoff_for_row\"]).dt.days\n",
    "    return df[df[\"days_from_cutoff\"].between(-bandwidth, bandwidth)].shape[0]\n",
    "\n",
    "GROUP_OBS = {\n",
    "    \"Pooled\": count_bandwidth_sample(merged_df, \"trip_start_date\", \"is_2020\", \"2020-01-06\", \"2019-01-07\", 15),\n",
    "    \"Low Income\": count_bandwidth_sample(merged_df_0, \"trip_start_date\", \"is_2020\", \"2020-01-06\", \"2019-01-07\", 15),\n",
    "    \"Mid Income\": count_bandwidth_sample(merged_df_2, \"trip_start_date\", \"is_2020\", \"2020-01-06\", \"2019-01-07\", 15),\n",
    "    \"High Income\": count_bandwidth_sample(merged_df_1, \"trip_start_date\", \"is_2020\", \"2020-01-06\", \"2019-01-07\", 15),\n",
    "}\n",
    "\n",
    "print(GROUP_OBS)\n",
    "\n",
    "export_grouped_rdit_to_tex(\n",
    "    summary_df=summary_df,\n",
    "    file_path=\"../../output/regression/rdit_group_table.tex\",\n",
    "    caption=\"Estimated Treatment Effects of the Congestion Tax across Income Groups\",\n",
    "    label=\"tab:tax_by_income\",\n",
    "    group_obs=GROUP_OBS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controller Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_controls_table_to_tex(\n",
    "    summary_df: pd.DataFrame,\n",
    "    file_path: str = \"controls_table.tex\",\n",
    "    sig_levels: list = [0.1, 0.05, 0.01],\n",
    "    caption: str = \"Estimated coefficients on control variables across income groups.\",\n",
    "    label: str = \"tab:controls_by_income\",\n",
    "    group_labels: dict = None,\n",
    "    controls_list: list = None,\n",
    "    control_labels: dict = None,\n",
    "    group_obs: dict = None  # ✅ 新增参数：每组观测数\n",
    "):\n",
    "    import os\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "    def get_stars(p):\n",
    "        if p < sig_levels[2]: return '***'\n",
    "        elif p < sig_levels[1]: return '**'\n",
    "        elif p < sig_levels[0]: return '*'\n",
    "        return ''\n",
    "\n",
    "    if controls_list is None:\n",
    "        controls_list = summary_df['variable'].tolist()\n",
    "\n",
    "    df = summary_df[summary_df[\"variable\"].isin(controls_list)].copy()\n",
    "    grouped = df.groupby(\"group\")\n",
    "    control_vars = sorted(df['variable'].unique().tolist())\n",
    "\n",
    "    columns = []\n",
    "    rows_coef = {var: [] for var in control_vars}\n",
    "    rows_se = {var: [] for var in control_vars}\n",
    "\n",
    "    group_keys = []\n",
    "    for group, subdf in grouped:\n",
    "        col_label = group_labels.get(group, group) if group_labels else group\n",
    "        columns.append(col_label)\n",
    "        group_keys.append(group)  # 原始 group 名称\n",
    "        subdf = subdf.set_index(\"variable\")\n",
    "        for var in control_vars:\n",
    "            if var in subdf.index:\n",
    "                coef = subdf.loc[var, 'coef']\n",
    "                se = subdf.loc[var, 'std_err']\n",
    "                pval = subdf.loc[var, 'P>|z|']\n",
    "                stars = get_stars(pval)\n",
    "                rows_coef[var].append(f\"{coef:.3f}{stars}\")\n",
    "                rows_se[var].append(f\"({se:.3f})\")\n",
    "            else:\n",
    "                rows_coef[var].append(\"–\")\n",
    "                rows_se[var].append(\" \")\n",
    "\n",
    "    tex_lines = [\n",
    "        \"\\\\begin{table}[H]\\\\centering\",\n",
    "        f\"\\\\caption{{{caption}}}\",\n",
    "        f\"\\\\label{{{label}}}\",\n",
    "        \"\\\\footnotesize\",\n",
    "        f\"\\\\begin{{tabular}}{{l{'c' * len(columns)}}}\",\n",
    "        \"\\\\toprule\",\n",
    "        \" & \" + \" & \".join(columns) + \" \\\\\\\\\",\n",
    "        \"\\\\midrule\"\n",
    "    ]\n",
    "\n",
    "    for var in control_vars:\n",
    "        display_name = control_labels.get(var, var).replace(\"_\", \"\\\\_\") if control_labels else var.replace(\"_\", \"\\\\_\")\n",
    "        tex_lines.append(display_name + \" & \" + \" & \".join(rows_coef[var]) + \" \\\\\\\\\")\n",
    "        tex_lines.append(\" & \" + \" & \".join(rows_se[var]) + \" \\\\\\\\\")\n",
    "\n",
    "    # ✅ 添加观测数行\n",
    "    if group_obs:\n",
    "        obs_row = [\"Observations\"]\n",
    "        for g in group_keys:\n",
    "            obs_row.append(str(group_obs.get(g, \"–\")))\n",
    "        tex_lines.append(\"\\\\midrule\")\n",
    "        tex_lines.append(\" & \".join(obs_row) + \" \\\\\\\\\")\n",
    "\n",
    "    tex_lines += [\n",
    "        \"\\\\bottomrule\",\n",
    "        \"\\\\end{tabular}\",\n",
    "        \"\\\\vspace{0.5em}\",\n",
    "        \"\\\\begin{minipage}{0.95\\\\textwidth}\\\\footnotesize\\\\textit{Notes:} Robust standard errors in parentheses. * $p < 0.1$, ** $p < 0.05$, *** $p < 0.01$.\\\\end{minipage}\",\n",
    "        \"\\\\end{table}\"\n",
    "    ]\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(tex_lines))\n",
    "\n",
    "    print(f\"LaTeX control variable table saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX control variable table saved to: ../../output/regression/rdit_controls_table.tex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_x/43n5hx2d6hqf1v6v65qbln8c0000gn/T/ipykernel_14770/2682482435.py:25: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped = df.groupby(\"group\")\n"
     ]
    }
   ],
   "source": [
    "# ✅ 设置 group 标签与顺序\n",
    "group_labels = {\n",
    "    \"Overall\": \"Pooled\",\n",
    "    \"Low\": \"Low Income\",\n",
    "    \"Mid\": \"Middle Income\",\n",
    "    \"High\": \"High Income\",\n",
    "}\n",
    "group_order = list(group_labels.keys())\n",
    "\n",
    "# ✅ 拼接 summary 并排序\n",
    "summary_df = pd.concat([\n",
    "    summary_pooled.assign(group=\"Overall\"),\n",
    "    summary_low.assign(group=\"Low\"),\n",
    "    summary_high.assign(group=\"High\"),\n",
    "    summary_mid.assign(group=\"Mid\"),\n",
    "])\n",
    "\n",
    "summary_df[\"group\"] = pd.Categorical(summary_df[\"group\"], categories=group_order, ordered=True)\n",
    "summary_df = summary_df.sort_values(\"group\")\n",
    "\n",
    "GROUP_OBS = {\n",
    "    \"Overall\": count_bandwidth_sample(merged_df, \"trip_start_date\", \"is_2020\", \"2020-01-06\", \"2019-01-07\", 15),\n",
    "    \"Low\": count_bandwidth_sample(merged_df_0, \"trip_start_date\", \"is_2020\", \"2020-01-06\", \"2019-01-07\", 15),\n",
    "    \"Mid\": count_bandwidth_sample(merged_df_2, \"trip_start_date\", \"is_2020\", \"2020-01-06\", \"2019-01-07\", 15),\n",
    "    \"High\": count_bandwidth_sample(merged_df_1, \"trip_start_date\", \"is_2020\", \"2020-01-06\", \"2019-01-07\", 15),\n",
    "}\n",
    "\n",
    "# ✅ 控制变量 label\n",
    "control_labels = {\n",
    "    \"trip_seconds\": \"Trip Duration (s)\",\n",
    "    \"trip_miles\": \"Trip Distance (miles)\",\n",
    "    \"trip_during_peak\": \"Peak Hour Trip\",\n",
    "    \"taxi\": \"Taxi Trips\",\n",
    "    # \"total_rides\": \"Public Transportation Rides\",\n",
    "    \"rides\": \"L Rail\",\n",
    "    \"daily_bus_rides\": \"Bus\",\n",
    "    \"Avg_Temp_C\": \"Temperature (°C)\",\n",
    "    \"Precipitation_mm\": \"Precipitation (mm)\",\n",
    "    \"Snowfall_mm\": \"Snowfall (mm)\",\n",
    "    \"Avg_Wind_Speed_mps\": \"Wind Speed (m/s)\",\n",
    "    \"dow_1\": \"Tuesday\",\n",
    "    \"dow_2\": \"Wednesday\",\n",
    "    \"dow_3\": \"Thursday\",\n",
    "    \"dow_4\": \"Friday\",\n",
    "    \"at_1\": \"Loop\",\n",
    "    \"at_2\": \"Tourist/Transit Area\",\n",
    "}\n",
    "\n",
    "# ✅ 导出表格\n",
    "export_controls_table_to_tex(\n",
    "    summary_df=summary_df,\n",
    "    file_path=\"../../output/regression/rdit_controls_table.tex\",\n",
    "    caption=\"Estimated Coefficients on Control Variables across Income Groups\",\n",
    "    label=\"tab:controls_by_income\",\n",
    "    group_labels=group_labels,\n",
    "    group_obs=GROUP_OBS,\n",
    "    controls_list=control_vars,\n",
    "    control_labels=control_labels\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
