{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16894a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "MERGED_DATA_DIR = \"../../data/merged data\"\n",
    "OUTPUT_DIR = \"../../output/assumption\"\n",
    "\n",
    "# Load the dataset\n",
    "tnp_20 = pd.read_csv(os.path.join(MERGED_DATA_DIR, \"2020\", \"merged_tnp_data.csv\"))\n",
    "tnp_19 = pd.read_csv(os.path.join(MERGED_DATA_DIR, \"2019\", \"merged_tnp_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a95d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加年份指示变量\n",
    "tnp_20[\"is_2020\"] = 1\n",
    "tnp_19[\"is_2020\"] = 0\n",
    "\n",
    "scaler = StandardScaler()\n",
    "cols_to_scale = [\"daily_bus_rides\", \"rides\"]\n",
    "tnp_20[cols_to_scale] = scaler.fit_transform(tnp_20[cols_to_scale])\n",
    "tnp_19[cols_to_scale] = scaler.fit_transform(tnp_19[cols_to_scale])\n",
    "\n",
    "# 拼接数据\n",
    "merged_df = pd.concat([tnp_20, tnp_19], ignore_index=True)\n",
    "merged_df[\"price\"] = merged_df[\"fare\"] + merged_df[\"additional_charges\"]\n",
    "# merged_df['price'] = np.log1p(merged_df['price'])\n",
    "\n",
    "# 确保日期变量是 datetime 类型（后续 RDiT 会用到）\n",
    "merged_df[\"trip_start_date\"] = pd.to_datetime(merged_df[\"trip_start_date\"])\n",
    "\n",
    "# 创建工作日虚拟变量，drop_first=True 是为了避免虚拟变量陷阱\n",
    "day_dummies = pd.get_dummies(merged_df['day_of_week'], prefix='dow', drop_first=True)\n",
    "\n",
    "# 合并到原始数据中\n",
    "merged_df = pd.concat([merged_df, day_dummies], axis=1)\n",
    "\n",
    "# 创建地区虚拟变量，drop_first=True 是为了避免虚拟变量陷阱\n",
    "area_dummies = pd.get_dummies(merged_df['area_type'], prefix='at', drop_first=True)\n",
    "\n",
    "# 合并到原始数据中\n",
    "merged_df = pd.concat([merged_df, area_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "510beec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总行数： 3187906\n",
      "是否有NaN： 0\n",
      "时间列范围： 2018-12-10 00:00:00 2020-02-05 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"数据总行数：\", len(merged_df))\n",
    "print(\"是否有NaN：\", merged_df[\"price\"].isna().sum())\n",
    "print(\"时间列范围：\", merged_df[\"trip_start_date\"].min(), merged_df[\"trip_start_date\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7463319",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_controls = [\n",
    "    \"trip_seconds\", \"trip_miles\", \"trip_during_peak\"\n",
    "]\n",
    "\n",
    "weather_controls = [\n",
    "    \"Avg_Temp_C\", \"Precipitation_mm\",\n",
    "    \"Snowfall_mm\", \"Avg_Wind_Speed_mps\",\n",
    "]\n",
    "\n",
    "substitutes_controls = [\n",
    "    # \"total_rides\", \"taxi\",\n",
    "    \"rides\", \"daily_bus_rides\", \"taxi\",\n",
    "]\n",
    "\n",
    "day_of_week_controls = [\"dow_1\", \"dow_2\", \"dow_3\", \"dow_4\"]\n",
    "\n",
    "area_type_controls = [\"at_1\", \"at_2\"]\n",
    "\n",
    "control_vars = (\n",
    "    trip_controls\n",
    "    + weather_controls\n",
    "    + substitutes_controls\n",
    "    + day_of_week_controls\n",
    "    + area_type_controls\n",
    ")\n",
    "\n",
    "merged_df_0 = merged_df[merged_df[\"Cluster\"] == 0]\n",
    "merged_df_1 = merged_df[merged_df[\"Cluster\"] == 1]\n",
    "merged_df_2 = merged_df[merged_df[\"Cluster\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aa1b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_dif_in_rdit(\n",
    "    df: pd.DataFrame,\n",
    "    outcome: str,\n",
    "    time_var: str,\n",
    "    treat_year_var: str,\n",
    "    cutoff_date,\n",
    "    placebo_cutoff_date=\"2019-01-07\",\n",
    "    heterogeneity_vars: list = None,\n",
    "    covariates: list = None,\n",
    "    trend_order: int = 1,\n",
    "    bandwidth: int = 29\n",
    "):\n",
    "    \"\"\"\n",
    "    估计Dif-in-RDiT模型，支持多个异质性变量（连续或虚拟变量）\n",
    "\n",
    "    数学模型：\n",
    "    Y_{it} = β0 + β1·Post_t + β2·TreatYear_i + β3·(Post_t·TreatYear_i)\n",
    "           + f(TFC_t) + f(TFC_t)·Post_t + f(TFC_t)·TreatYear_i + f(TFC_t)·Post_t·TreatYear_i\n",
    "           + ∑ δ_k·H_{ik} + ∑ θ_k·(Post_t·H_{ik}) + γ^T X + u_{it}\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import statsmodels.formula.api as smf\n",
    "\n",
    "    df = df.copy()\n",
    "    df[time_var] = pd.to_datetime(df[time_var])\n",
    "    cutoff_date = pd.to_datetime(cutoff_date)\n",
    "    placebo_cutoff_date = pd.to_datetime(placebo_cutoff_date)\n",
    "\n",
    "    df[\"cutoff_for_row\"] = df[treat_year_var].apply(\n",
    "        lambda x: cutoff_date if x == 1 else placebo_cutoff_date\n",
    "    )\n",
    "    df[\"days_from_cutoff\"] = (df[time_var] - df[\"cutoff_for_row\"]).dt.days\n",
    "    df = df[df[\"days_from_cutoff\"].between(-bandwidth, bandwidth)]\n",
    "\n",
    "    df[\"post_cutoff\"] = (df[\"days_from_cutoff\"] >= 0).astype(int)\n",
    "    df[\"post_treat\"] = df[\"post_cutoff\"] * df[treat_year_var]\n",
    "\n",
    "    trend_terms = []\n",
    "    for i in range(1, trend_order + 1):\n",
    "        base = f\"days_from_cutoff_pow{i}\"\n",
    "        df[base] = df[\"days_from_cutoff\"] ** i\n",
    "\n",
    "        post = f\"{base}_x_post\"\n",
    "        treat = f\"{base}_x_treat\"\n",
    "        post_treat = f\"{base}_x_post_treat\"\n",
    "\n",
    "        df[post] = df[base] * df[\"post_cutoff\"]\n",
    "        df[treat] = df[base] * df[treat_year_var]\n",
    "        df[post_treat] = df[base] * df[\"post_cutoff\"] * df[treat_year_var]\n",
    "\n",
    "        trend_terms += [base, post, treat, post_treat]\n",
    "\n",
    "    rhs = [\"post_cutoff\", treat_year_var, \"post_treat\"] + trend_terms\n",
    "\n",
    "    if covariates:\n",
    "        rhs += covariates\n",
    "\n",
    "    interaction_terms = []\n",
    "    if heterogeneity_vars:\n",
    "        for var in heterogeneity_vars:\n",
    "            rhs.append(var)  # H_k\n",
    "            inter = f\"post_cutoff:{var}\"  # Post_t * H_k\n",
    "            rhs.append(inter)\n",
    "            interaction_terms.append(inter)\n",
    "\n",
    "    formula = f\"{outcome} ~ \" + \" + \".join(rhs)\n",
    "    model = smf.ols(formula=formula, data=df).fit(cov_type='HC3')\n",
    "\n",
    "    summary_df = model.summary2().tables[1].copy()\n",
    "    summary_df.columns = summary_df.columns.astype(str)\n",
    "    summary_df = summary_df.rename(columns={\n",
    "        \"Coef.\": \"coef\",\n",
    "        \"Std.Err.\": \"std_err\",\n",
    "        \"P>|t|\": \"p_value\",\n",
    "        \"[0.025\": \"ci_lower\",\n",
    "        \"0.975]\": \"ci_upper\"\n",
    "    })\n",
    "    summary_df[\"variable\"] = summary_df.index\n",
    "    summary_df.reset_index(drop=True, inplace=True)\n",
    "    print(model.rsquared)\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76b7dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7795886814191689\n",
      "0.7798326270812114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 39, but rank is 35\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7798886542605641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 47, but rank is 34\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7799060793012614\n",
      "0.8139738498096765\n",
      "0.813999185270152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 39, but rank is 35\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8141217642183834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 47, but rank is 34\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814140795669363\n",
      "0.7688939921582473\n",
      "0.7691713282723608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 39, but rank is 35\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7692273914734633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 47, but rank is 34\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7692497946709709\n",
      "0.7951670006904098\n",
      "0.7953920485430735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 39, but rank is 35\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7954787081529067\n",
      "0.7955197489622321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 47, but rank is 34\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "def run_robustness_all_trend_orders():\n",
    "    dfs = {\n",
    "        \"pooled\": merged_df,\n",
    "        \"low\": merged_df_0,\n",
    "        \"high\": merged_df_1,\n",
    "        \"mid\": merged_df_2\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    for name, df in dfs.items():\n",
    "        results[name] = {}\n",
    "        for trend in [1, 3]:  # trend_order 从 1 到 4\n",
    "            summary = estimate_dif_in_rdit(\n",
    "                df=df,\n",
    "                outcome=\"price\",\n",
    "                time_var=\"trip_start_date\",\n",
    "                treat_year_var=\"is_2020\",\n",
    "                cutoff_date=\"2020-01-06\",\n",
    "                placebo_cutoff_date=\"2019-01-07\",\n",
    "                covariates=control_vars,\n",
    "                heterogeneity_vars=None,\n",
    "                trend_order=trend,\n",
    "                bandwidth=15\n",
    "            )\n",
    "            results[name][f\"trend_order_{trend}\"] = summary\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 调用一次就能跑完所有情况\n",
    "all_results = run_robustness_all_trend_orders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d79a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_trend_order_heterogeneity_table_to_tex(\n",
    "    summary_df: pd.DataFrame,\n",
    "    file_path: str = \"output/custom_trend_hetero_table.tex\",\n",
    "    sig_levels: list = [0.1, 0.05, 0.01],\n",
    "    caption: str = \"Estimated effects across income groups and trend orders.\",\n",
    "    label: str = \"tab:custom_trend_hetero\",\n",
    "    group_order: list = None,\n",
    "    trend_order_list: list = None\n",
    "):\n",
    "    \"\"\"\n",
    "    生成 LaTeX 表格，行是 trend_order，列是组，表格内容以 makecell 包装支持单元格内换行。\n",
    "    \"\"\"\n",
    "    import os\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "    def get_stars(p):\n",
    "        if p < sig_levels[2]: return '***'\n",
    "        elif p < sig_levels[1]: return '**'\n",
    "        elif p < sig_levels[0]: return '*'\n",
    "        return ''\n",
    "\n",
    "    df = summary_df[summary_df[\"variable\"] == \"post_treat\"].copy()\n",
    "\n",
    "    if trend_order_list is None:\n",
    "        trend_order_list = sorted(df[\"trend_order\"].dropna().unique())\n",
    "    if group_order is None:\n",
    "        group_order = df[\"hetero_group\"].dropna().unique().tolist()\n",
    "\n",
    "    tex_lines = [\n",
    "        \"\\\\begin{table}[H]\\\\centering\",\n",
    "        \"\\\\renewcommand{\\\\arraystretch}{1.3}\",\n",
    "        \"\\\\caption{\" + caption + \"}\",\n",
    "        \"\\\\label{\" + label + \"}\",\n",
    "        \"\\\\footnotesize\",\n",
    "        \"\\\\begin{tabular}{l\" + \"c\" * len(group_order) + \"}\",\n",
    "        \"\\\\toprule\",\n",
    "        \"Trend Order & \" + \" & \".join(group_order) + \" \\\\\\\\\",\n",
    "        \"\\\\midrule\"\n",
    "    ]\n",
    "\n",
    "    for trend in trend_order_list:\n",
    "        row = [f\"Order {int(trend)}\"]\n",
    "        for grp in group_order:\n",
    "            sub = df[(df[\"trend_order\"] == trend) & (df[\"hetero_group\"] == grp)]\n",
    "            if not sub.empty:\n",
    "                r = sub.iloc[0]\n",
    "                cell = f\"\\\\makecell{{{r['coef']:.3f}{get_stars(r['P>|z|'])} \\\\\\\\ ({r['std_err']:.3f})}}\"\n",
    "            else:\n",
    "                cell = \"--\"\n",
    "            row.append(cell)\n",
    "        tex_lines.append(\" & \".join(row) + \" \\\\\\\\\")\n",
    "\n",
    "    tex_lines += [\n",
    "        \"\\\\bottomrule\",\n",
    "        \"\\\\end{tabular}\",\n",
    "        \"\\\\vspace{0.5em}\",\n",
    "        \"\\\\begin{minipage}{0.95\\\\textwidth}\\\\footnotesize\\\\textit{Notes:} This table reports the estimated treatment effects under different trend orders. Each cell shows the coefficient and the robust standard error (in parentheses). * $p<0.1$, ** $p<0.05$, *** $p<0.01$.\\\\end{minipage}\",\n",
    "        \"\\\\end{table}\"\n",
    "    ]\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(tex_lines))\n",
    "\n",
    "    print(f\"LaTeX table saved to: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eb05cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX table saved to: ../../output/robustness/rdit_across_trend_orders.tex\n"
     ]
    }
   ],
   "source": [
    "def flatten_results(all_results):\n",
    "    \"\"\"\n",
    "    把 all_results (字典) 转成一个扁平的 DataFrame，附上 group 和 trend_order 标记。\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for group, trend_results in all_results.items():\n",
    "        for trend_key, df in trend_results.items():\n",
    "            trend_order = int(trend_key.split(\"_\")[-1])  # 提取 trend_order\n",
    "            temp_df = df.copy()\n",
    "            temp_df[\"hetero_group\"] = group\n",
    "            temp_df[\"trend_order\"] = trend_order\n",
    "            rows.append(temp_df)\n",
    "    return pd.concat(rows, ignore_index=True)\n",
    "\n",
    "flattened_df = flatten_results(all_results)\n",
    "\n",
    "# 第二步：再导出\n",
    "export_trend_order_heterogeneity_table_to_tex(\n",
    "    summary_df=flattened_df,\n",
    "    file_path=\"../../output/robustness/rdit_across_trend_orders.tex\",\n",
    "    caption=\"Treatment effects across trend orders.\",\n",
    "    label=\"tab:trend_order_hetero\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
